{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": "For an input view, traverses the view dependency hierarchy to get a list of distinct OPENROWSET sources paths.  Then, it looks ta our notebooks to see how those sources (delta tables, etc.) are populated. A work in progress. ",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Input: View Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [],
      "metadata": {},
      "source": [
        "# This is our input view.  \n",
        "# It needs to be 2-part named using square bracket identifier delimiters\n",
        "# e.g. \"[export].[Board_Intake]\"\"\n",
        "qualified_view_name = \"[export].[Board_Intake]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyodbc\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Includes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [],
      "metadata": {},
      "source": [
        "%run common_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Python Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [],
      "metadata": {},
      "source": [
        "def parse_object_name(qualified_view_name: str):\n",
        "    \"\"\"\n",
        "    Parse a quoted/qualified object name of the form [SchemaName].[ViewName]\n",
        "    and return (SchemaName, ViewName) without the brackets.\n",
        "    \"\"\"\n",
        "    # Use regex to capture names inside square brackets\n",
        "    matches = re.findall(r\"\\[([^\\]]+)\\]\", qualified_view_name)\n",
        "    \n",
        "    if len(matches) == 2:\n",
        "        return matches[0], matches[1]\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid qualified name format: {qualified_view_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "outputs": [],
      "metadata": {},
      "source": [
        "def run_batch_return_last_df(conn, sql: str, params=None):\n",
        "    \"\"\"Execute a multi-statement batch and return ONLY the last SELECT as a pandas DataFrame.\"\"\"\n",
        "    import pandas as pd\n",
        "    with conn.cursor() as cur:\n",
        "        cur.execute(sql, params or [])\n",
        "        last_rows, last_cols = None, None\n",
        "        while True:\n",
        "            if cur.description is not None:          # this statement produced a result set\n",
        "                last_cols  = [d[0] for d in cur.description]\n",
        "                last_rows  = cur.fetchall()          # keep overwriting -> we keep the LAST\n",
        "            if not cur.nextset():                    # advance to next statement's result set; stop at end\n",
        "                break\n",
        "    if last_rows is None:\n",
        "        return pd.DataFrame()\n",
        "    return pd.DataFrame.from_records(last_rows, columns=last_cols)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "outputs": [],
      "metadata": {},
      "source": [
        "# --- helper to extract 'BULK' / 'DATA_SOURCE' / 'FORMAT' string values (handles ' or \")\n",
        "def _find_arg(block: str, keyword: str):\n",
        "    # Matches: KEYWORD [=] 'value'  or  \"value\"  (optional N prefix)\n",
        "    pat = rf\"\\b{keyword}\\b\\s*(?:=\\s*)?(?:N)?(?P<q>['\\\"])(?P<val>.*?)(?P=q)\"\n",
        "    m = re.search(pat, block, flags=re.IGNORECASE | re.DOTALL)\n",
        "    return m.group(\"val\").strip() if m else None\n",
        "\n",
        "def parse_openrowset(block: str):\n",
        "    return {\n",
        "        \"bulk\":        _find_arg(block, \"BULK\"),\n",
        "        \"data_source\": _find_arg(block, \"DATA_SOURCE\"),\n",
        "        \"format\":      (_find_arg(block, \"FORMAT\") or None)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# SQL Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Our View Dependency SQL Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "outputs": [],
      "metadata": {},
      "source": [
        "# our view dependency query:\n",
        "# We use view_name from above to filter the results.\n",
        "sql_view_dependencies = \"\"\"\n",
        ";WITH cte AS\n",
        "(\n",
        "\t--Root level ****************************************************\n",
        "\tSELECT \n",
        "\t\tNestLevel = 0\n",
        "\t\t,QUOTENAME(SCHEMA_NAME(o.schema_id)) + N'.' + QUOTENAME(o.name) AS RootObjectName \n",
        "\t\t,CAST(COALESCE(QUOTENAME(SCHEMA_NAME(o.schema_id)) + N'.' + QUOTENAME(o.name) + N'->' +\n",
        "\t\t\t-- optional server\n",
        "\t\t\tCOALESCE(QUOTENAME(sed.referenced_server_name) + N'.', '') +\n",
        "\t\t\t-- optional DB\n",
        "\t\t\tCOALESCE(QUOTENAME(sed.referenced_database_name) + N'.', '') +\n",
        "\t\t\t-- schema (not always there\n",
        "\t\t\tCOALESCE(QUOTENAME(sed.referenced_schema_name) + N'.', '') +\n",
        "\t\t\t-- object\n",
        "\t\t\tQUOTENAME(sed.referenced_entity_name), QUOTENAME(SCHEMA_NAME(o.schema_id)) + N'.' + QUOTENAME(o.name)) AS NVARCHAR(MAX))\n",
        "\t\t\tAS CallHierarchy\n",
        "\t\t,SCHEMA_NAME(o.schema_id) AS ParentSchemaName\n",
        "\t\t,o.name AS ParentObjectName\n",
        "\t\t,o.type_desc AS ParentObjectType\n",
        "\t\t,sed.referenced_server_name AS ChildServerName\n",
        "\t\t,sed.referenced_database_name AS ChildDatabaseName\n",
        "\t\t,sed.referenced_id AS ChildObjectID\n",
        "\t\t,sed.referenced_schema_name AS ChildSchemaName\n",
        "\t\t,sed.referenced_entity_name AS ChildObjectName\n",
        "\t\t,oReferenced.type_desc AS ChildObjectType\n",
        "\tFROM\n",
        "\t\tsys.objects AS o\n",
        "\t\tLEFT JOIN sys.sql_expression_dependencies AS sed \n",
        "\t\t\tON(o.object_id = sed.referencing_id) \n",
        "\t\t-- what is the referenced entity type?\n",
        "\t\tLEFT JOIN sys.objects AS oReferenced\n",
        "\t\t\tON(sed.referenced_id = oReferenced.object_id)\n",
        "\tWHERE\n",
        "\t\to.type IN ('FN', 'IF', 'TF', 'P', 'V')\n",
        "\t\tAND o.is_ms_shipped = 0\n",
        "\n",
        "\t-- OK - now we make it recursive - traverse the hierarchy\n",
        "\tUNION ALL\n",
        "\n",
        "\t-- decendant query ********************************\n",
        "\tSELECT \n",
        "\t\tNestLevel = c.NestLevel + 1\n",
        "\t\t,c.RootObjectName\n",
        "\t\t,c.CallHierarchy + CAST(N'->' +\n",
        "\t\t\t-- optional server\n",
        "\t\t\tCOALESCE(QUOTENAME(sed.referenced_server_name) + N'.', '') +\n",
        "\t\t\t-- optional DB\n",
        "\t\t\tCOALESCE(QUOTENAME(sed.referenced_database_name) + N'.', '') +\n",
        "\t\t\t-- schema (not always there\n",
        "\t\t\tCOALESCE(QUOTENAME(sed.referenced_schema_name) + N'.', '') +\n",
        "\t\t\t-- object\n",
        "\t\t\tQUOTENAME(sed.referenced_entity_name) AS NVARCHAR(MAX))\n",
        "\t\t\tAS CallHierarchy\n",
        "\t\t,c.ChildSchemaName AS ParentSchemaName\n",
        "\t\t,c.ChildObjectName AS ParentObjectName\n",
        "\t\t,c.ChildObjectType AS ParentObjectType\n",
        "\t\t,sed.referenced_server_name AS ChildServerName\n",
        "\t\t,sed.referenced_database_name AS ChildDatabaseName\n",
        "\t\t,sed.referenced_id AS ChildObjectID\n",
        "\t\t,sed.referenced_schema_name AS ChildSchemaName\n",
        "\t\t,sed.referenced_entity_name AS ChildObjectName\n",
        "\t\t--,sed.type_desc AS ChildObjectType\n",
        "\t\t,oReferenced.type_desc AS ChildObjectType\n",
        "\tFROM\n",
        "\t\tcte AS c \n",
        "\t\t-- Take the previous iterations CTE Child/referenced and see if we find a parent/referencing \n",
        "\t\t-- sql expr for it.\n",
        "\t\t-- This is the essence of the recursion.\n",
        "\t\tINNER JOIN sys.sql_expression_dependencies AS sed\n",
        "\t\t\tON(c.ChildObjectID = sed.referencing_id)\n",
        "\t\tOUTER APPLY (SELECT * FROM sys.objects AS oReferenced1 WHERE sed.referenced_id = oReferenced1.object_id) AS oReferenced\n",
        "\tWHERE\n",
        "\t\t1=1\n",
        "\t\tAND (sed.referencing_id <> sed.referenced_id OR sed.referenced_id IS NULL) -- We DO need this to make sure it's not a recurive call, but also need to handle cross DB null referenced_id \n",
        ")\n",
        "SELECT \n",
        "\t@@SERVERNAME AS ServerName\n",
        "\t,DB_NAME() AS DatabaseName\n",
        "\t,c.*\n",
        "INTO #dep\n",
        "--\tDependencyCollector.dbo.SQLDependency\n",
        "FROM\n",
        "\tcte AS c\n",
        "ORDER BY\n",
        "\tc.RootObjectName\n",
        "\t,c.NestLevel\n",
        "\n",
        "-- ***************************************************************************************************************\n",
        "-- Now we can select from #dep and query it however we want to:\n",
        "SELECT\n",
        "\t*\n",
        "FROM\n",
        "\t#dep AS d\n",
        "WHERE\n",
        "\td.RootObjectName = ? --'[export].[Board_Intake]'\n",
        "ORDER BY\n",
        "\td.RootObjectName\n",
        "\t,d.NestLevel\n",
        "\t,d.ChildSchemaName\n",
        "\t,d.ChildObjectName\n",
        "\"\"\"\n",
        "\n",
        "#print(sql_view_dependencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Get object_id from schema and view name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Query to get object_id from view name and schema name\n",
        "sql_get_view_object_id = \"\"\"\n",
        "select \n",
        "\tv.object_id\n",
        "from\n",
        "\tsys.views as v\n",
        "where\n",
        "\tv.name = ?\n",
        "\tand SCHEMA_NAME(v.schema_id) = ?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Get view definition for object_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Query to lookup view definitions for a view via object_id\n",
        "# so we can parse out the OPENROWSETs that we find\n",
        "sql_view_def = \"\"\"\n",
        "select\n",
        "\tsm.definition\n",
        "from\n",
        "\tsys.sql_modules as sm\n",
        "where\n",
        "\tsm.object_id = ? --(1711345161)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Get our Serverless SQL Connection Info, Including Creds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Set our SQL Endpoint URL (prod), DB, user\n",
        "serverless_server = \"azwwwprodprdadapsyn01-ondemand.sql.azuresynapse.net\"\n",
        "database         = \"sql\"\n",
        "username         = \"util\"\n",
        "\n",
        "# Get our util SQL login/user password from AKV\n",
        "secret_name = \"util-sql-login-password\"    \n",
        "\n",
        "# Retrieve the secret value\n",
        "password = mssparkutils.credentials.getSecret(kv_name, secret_name)\n",
        "\n",
        "# (Optional) sanity check: do not print secrets!\n",
        "print(f\"Retrieved password for secret '{secret_name}' (length={len(password)})\")\n",
        "\n",
        "# Configure and build our connection (conn) object\n",
        "conn_str = (\n",
        "    \"Driver={ODBC Driver 18 for SQL Server};\"\n",
        "    f\"Server=tcp:{serverless_server},1433;\"\n",
        "    f\"Database={database};\"\n",
        "    f\"Uid={username};\"\n",
        "    f\"Pwd={password};\"\n",
        "    \"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=60;\"\n",
        ")\n",
        "\n",
        "conn = pyodbc.connect(conn_str)\n",
        "conn.autocommit = True  # serverless-friendly; avoids implicit transactions\n",
        "print(\"PyODBC Connection object conn built.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Get the dependecies for our input view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "outputs": [],
      "metadata": {},
      "source": [
        "# query our dependencies and get them as a list of dicts.\n",
        "# view_name is set at the top of the notebook.\n",
        "pdf = run_batch_return_last_df(conn, sql_view_dependencies, qualified_view_name)\n",
        "#pdf.head()\n",
        "print(f\"pdf.count() = {len(pdf)}\")\n",
        "\n",
        "# Get distinct rows\n",
        "df_unique_children = (\n",
        "    pdf[[\"ChildObjectID\", \"ChildSchemaName\", \"ChildObjectName\"]]\n",
        "    .drop_duplicates()\n",
        ")\n",
        "\n",
        "# rename columns\n",
        "# Rename columns before converting\n",
        "df_unique_children = df_unique_children.rename(\n",
        "    columns={\n",
        "        \"ChildObjectID\": \"object_id\",\n",
        "        \"ChildSchemaName\": \"schema_name\",\n",
        "        \"ChildObjectName\": \"view_name\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Convert to list of dicts\n",
        "view_list = df_unique_children.to_dict(orient=\"records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Find OPENROWSET refs in all of our views, including the root one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Get the full list of views to analyze, incuding the root one (input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Parse out the schema name and view name from the quoted qualified name\n",
        "schema_name, view_name = parse_object_name(qualified_view_name)\n",
        "print(f\"view_name = {view_name}\")\n",
        "print(f\"schema_name = {schema_name}\")\n",
        "\n",
        "# Get the object_id for our root view\n",
        "pdf = run_batch_return_last_df(conn, sql_get_view_object_id, [view_name, schema_name])\n",
        "#print(f\"pdf.count() = {len(pdf)}\")\n",
        "#display(pdf)\n",
        "root_object_id = pdf[\"object_id\"].iloc[0]\n",
        "print(f\"root_object_id = {root_object_id}\")\n",
        "\n",
        "# Add this root view info to the list of object_ids for child views \n",
        "view_list.append({\n",
        "    \"object_id\": root_object_id,\n",
        "    \"schema_name\": schema_name,\n",
        "    \"view_name\": view_name\n",
        "})\n",
        "\n",
        "print(\"We will be looking at these views:\")\n",
        "print(view_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Get the view definition of each and extract the OPENROWSET call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "outputs": [],
      "metadata": {},
      "source": [
        "print(\"Parsing view DDL for OPENROWSET calls...\")\n",
        "parsed_rows = []\n",
        "for view in view_list:\n",
        "    object_id = int(view[\"object_id\"])\n",
        "    schema_name = view[\"schema_name\"]\n",
        "    view_name = view[\"view_name\"]\n",
        "\n",
        "    print(f\"Processing object_id {object_id}: [{schema_name}].[{view_name}]\")\n",
        "\n",
        "    # Get the view DDL (definition) for this view\n",
        "    pdf_view_def = run_batch_return_last_df(conn, sql_view_def, [object_id])\n",
        "    view_definition = pdf_view_def[\"definition\"].iloc[0]\n",
        "\n",
        "    # TODO Now get all of the OPENROWSET calls from the defintion \n",
        "    # Find each OPENROWSET(...) call (no nested parentheses inside the arg list)\n",
        "    openrowset_pattern = re.compile(r\"OPENROWSET\\s*\\([^)]*\\)\", re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    calls = openrowset_pattern.findall(view_definition)\n",
        "    # calls is a list of strings like: \"OPENROWSET( BULK '...', DATA_SOURCE = '...', FORMAT = 'DELTA' )\"   \n",
        "\n",
        "    # Extract the BULK, DATA_SOURCE and FORMAT parameters for each OPENROWSET.\n",
        "    if len(calls) == 0:\n",
        "        print(f\"No direct OPENROWSET calls found in object_id {object_id}: [{schema_name}].[{view_name}].\")\n",
        "        continue\n",
        "\n",
        "    for call in calls:\n",
        "        info = parse_openrowset(call)\n",
        "        # optional normalization\n",
        "        if info[\"format\"]:\n",
        "            info[\"format\"] = info[\"format\"].upper()\n",
        "        parsed_rows.append({\n",
        "            \"object_id\": object_id,\n",
        "            \"schema_name\": schema_name,\n",
        "            \"view_name\": view_name,\n",
        "            **info\n",
        "        })\n",
        "\n",
        "print(\"Finished parsing view DDL for OPENROWSET calls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Display our findings - we can export this to CSV, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Print our findings\n",
        "#print(parsed_rows)\n",
        "\n",
        "# Use your list variable here:\n",
        "rows = parsed_rows  # or: rows = all_rows\n",
        "\n",
        "cols = [\"object_id\", \"schema_name\", \"view_name\", \"bulk\", \"data_source\", \"format\"]\n",
        "df = pd.DataFrame(rows)[cols].sort_values(\n",
        "    [\"schema_name\", \"view_name\", \"bulk\", \"data_source\"]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "# Notebook-friendly display\n",
        "display(df)              "
      ]
    }
  ]
}