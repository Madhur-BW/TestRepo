{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Revision History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Change_date         revision_number     change_description                           author\r\n",
        "# 02/08/2024          1                   initial check-in                             Kranthi\r\n",
        "# 05/03/2024          2                    made it dynamic to load for GUA and GA4      Kranthi\r\n",
        "## first load for one date - then generate the schema using printSchema- create its structype for all the fields\r\n",
        "## then start loading for all partitions. Create static schema first and then load all partitions in parallel. \r\n",
        "##The following things were tried and gave error::\r\n",
        "## 1. with out schema defination, with out empty table table - load all partitions in parallel - protocol version error\r\n",
        "## 2. first load 20230205 and then load all partitions in parllel- metadata changed by concurrent update error\r\n",
        "## 3. create empty table with schema defined - then load all partitions in parallel - metadata changed by concurrent update error.\r\n",
        "## 4. create empty table with schema defined - load single partition 20240501 - then load all other partitions - worked successfully\r\n",
        "## Similarly for GUA , create the schema and load single 20230204 - then load all other partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import concurrent.futures\r\n",
        "from delta import *\r\n",
        "from pyspark.sql.types import StructType, StructField, ArrayType, StringType, LongType, DoubleType, BooleanType, MapType,IntegerType\r\n",
        "from pyspark.sql.functions import *\r\n",
        "from functools import reduce\r\n",
        "from pyspark.sql.dataframe import DataFrame\r\n",
        "import pyspark.sql.functions as F\r\n",
        "import json\r\n",
        "import base64\r\n",
        "from datetime import datetime,timedelta\r\n",
        "from time import sleep\r\n",
        "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"DYNAMIC\")\r\n",
        "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run /utils/common_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## define a dict for all brands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "property_brand  = {309713727:'Bates US'\r\n",
        ",309561205:'CatFootwear Canada'\r\n",
        ",309621431:'CatFootwear DE'\r\n",
        ",309599233:'CatFootwear EMEAEmerging'\r\n",
        ",309613069:'CatFootwear UK'\r\n",
        ",309592771:'CatFootwear US'\r\n",
        ",309589213:'Chacos US'\r\n",
        ",309616895:'HushPuppies Canada'\r\n",
        ",309650146:'HushPuppies US'\r\n",
        ",309619975:'Hytest US'\r\n",
        ",309607124:'Keds Canada'\r\n",
        ",309606225:'Merrell BE'\r\n",
        ",309607810:'Merrell Canada'\r\n",
        ",309615440:'Merrell DE'\r\n",
        ",309628914:'Merrell EMEAEmerging'\r\n",
        ",309620743:'Merrell ES'\r\n",
        ",309579645:'Merrell FR'\r\n",
        ",309621834:'Merrell NL'\r\n",
        ",309591477:'Merrell SE'\r\n",
        ",309599329:'Merrell UK'\r\n",
        ",309592118:'OnlineShoes US'\r\n",
        ",310709711:'Saucony AT'\r\n",
        ",309600562:'Saucony BE'\r\n",
        ",309596198:'Saucony Canada'\r\n",
        ",309624452:'Saucony DE'\r\n",
        ",309643444:'Saucony EMEAEmerging'\r\n",
        ",309629089:'Saucony ES'\r\n",
        ",309607948:'Saucony FR'\r\n",
        ",309537329:'Saucony IT'\r\n",
        ",309603632:'Saucony NL'\r\n",
        ",309587387:'Saucony UK'\r\n",
        ",309650574:'Sperry Canada'\r\n",
        ",309632059:'Sperry US'\r\n",
        ",309599656:'Wolverine Canada'\r\n",
        ",309591384:'Wolverine US'\r\n",
        ",309617502:'Merrell US'\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "project = \"ga360-connection-267115\"\r\n",
        "\r\n",
        "token_library = sc._jvm.com.microsoft.azure.synapse.tokenlibrary.TokenLibrary  \r\n",
        "#token_library.getSecret(\"kv-name\", \"secret-name\", \"linked-service\")  \r\n",
        "ga4_credentials = token_library.getSecret(kv_name, \"GA4-credentials\", \"ls_kv_adap\")  \r\n",
        "print(ga4_credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "\r\n",
        "spark.conf.set(\"viewsEnabled\",\"true\")\r\n",
        "#spark.conf.set(\"materializationDataset\",\"ga360-connection-267115.analytics_297479542.events_20240201\")\r\n",
        "spark.conf.set(\"materializationDataset\",\"analytics_297479542\")\r\n",
        "def get_property_partitions(p_property_id): \r\n",
        "    print('get partitions for property::',p_property_id)\r\n",
        "    property_date_tup_list = []\r\n",
        "    yr = '>20231108' \r\n",
        "    table_name = \" (table_name like 'events_2023%' or table_name like 'events_2024%')\" \r\n",
        "    projection1 = \"cast(split(table_name,'_')[OFFSET(1)] as INT64)\"\r\n",
        "    print('yr::',yr)           \r\n",
        "    df_info_schema = spark.read.format(\"bigquery\")\\\r\n",
        "        .option(\"credentials\",ga4_credentials)\\\r\n",
        "        .option(\"parentProject\",'ga360-connection-267115')\\\r\n",
        "        .load(f\"\"\"select {projection1} as partition_no, * \r\n",
        "            from `ga360-connection-267115.analytics_{p_property_id}.INFORMATION_SCHEMA.TABLES`\r\n",
        "            where table_schema = 'analytics_{p_property_id}'   \r\n",
        "            and {table_name}     \r\n",
        "            and {projection1}{yr}\r\n",
        "       \"\"\")\r\n",
        "    #display(df_info_schema)   \r\n",
        "    for j in df_info_schema.collect():\r\n",
        "        property_date_tup_list.append((j.table_name,p_property_id))\r\n",
        "    return  property_date_tup_list    \r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\r\n",
        "ga4_or_gau = 'GA4'\r\n",
        "#ga4_or_gau = 'GA4/history'\r\n",
        "lineage_source = 'GA4'\r\n",
        "#lineage_source = 'GUA'\r\n",
        "def ingest_bq_data(p_table_name,p_property_id):\r\n",
        "  try:\r\n",
        "    print('p_table_name::',p_table_name,'p_property_id::',p_property_id)\r\n",
        "\r\n",
        "    brand = property_brand[p_property_id].split(' ')[0]\r\n",
        "    brand_country = property_brand[p_property_id].split(' ')[-1]\r\n",
        "    #print(\"part_name::\",part_name,\"brand::\",brand)\r\n",
        "    table = f'{project}.analytics_{p_property_id}.{p_table_name}'\r\n",
        "    df = spark.read.format(\"bigquery\") \\\r\n",
        "    .option(\"parentProject\",project)\\\r\n",
        "    .option(\"table\", table) \\\r\n",
        "    .option(\"credentials\",ga4_credentials) \\\r\n",
        "    .load()\r\n",
        "    #.where(\"event_name IN ('view_item', 'add_to_cart') \")\r\n",
        "    df = df.withColumn('property_brand',lit(brand))\\\r\n",
        "           .withColumn('brand_country',lit(brand_country))\\\r\n",
        "           .withColumn('lineage_source',lit(lineage_source))\r\n",
        "    #df_all_ingest.append(df)\r\n",
        "    df.repartition('event_date','property_brand','brand_country')\\\r\n",
        "    .write.format(\"delta\")\\\r\n",
        "    .mode(\"append\")\\\r\n",
        "    .option(\"path\",f\"{raw_adls_path}{ga4_or_gau}/events\")\\\r\n",
        "    .option(\"mergeSchema\", \"true\")\\\r\n",
        "    .partitionBy('event_date','property_brand','brand_country')\\\r\n",
        "    .save()\r\n",
        "  except Exception as e:\r\n",
        "    print('Other exception::','p_table_name::',p_table_name,'p_property_id::',p_property_id,'::',str(e)) \r\n",
        "    raise \r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# MAIN Call - get data from BQ and write to ADLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def load_all_data():\r\n",
        "  for i,j in property_brand.items():\r\n",
        "    print('processing:: ',j )\r\n",
        "    dates_list = get_property_partitions(i)\r\n",
        "    dates_list = list(set([x for x in dates_list ]))    \r\n",
        "    table_list = list(set(dates_list))\r\n",
        "    #print(sorted(table_list))\r\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\r\n",
        "            results = list(executor.map(ingest_bq_data, *zip(*table_list)))\r\n",
        "   \r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## call load_all_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "load_all_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Validate the counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "-- select event_date , event_params, event_params.product_price.double_value\r\n",
        "-- ,items.item_id\r\n",
        "--  ,items.quantity\r\n",
        "--  ,items.item_params\r\n",
        "--  from delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/events/` limit 10\r\n",
        "--refresh table delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/events/`;\r\n",
        "select event_date,property_brand,brand_country,count(*) \r\n",
        "from delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/events/`\r\n",
        "group by event_date,property_brand,brand_country;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "-- select count(*) from delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/events/`\r\n",
        "create table if not exists raw.ga4_events\r\n",
        "USING DELTA select * from delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/events/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "--select count(*) from raw.ga4_events where event_date = 20240501\r\n",
        "--select count(*) from raw.ga4_events where event_date between 20240421 and 20240427\r\n",
        "--and event_name = 'session_start';\r\n",
        "\r\n",
        "select device.category, count(distinct user_pseudo_id)  as session_count\r\n",
        "from raw.ga4_events where event_date between 20240421 and 20240427\r\n",
        "and event_name = 'session_start'\r\n",
        "    group by device.category\r\n",
        "--select distinct event_name from raw.ga4_events where event_date between 20240421 and 20240427"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "select  count(*) \r\n",
        "from  raw.ga4_events\r\n",
        "groue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "-- show create table raw.ga4_events \r\n",
        "-- describe detail delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/events/`\r\n",
        "select property_brand, min(event_date) \r\n",
        "from delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/history/events/`\r\n",
        "group by property_brand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "df_gua= spark.read.format('delta').load('abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/GA4/history/events/')\r\n",
        "df_gua.printSchema()\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "-- select count(*), event_date from raw.ga4_events\r\n",
        "-- where property_brand =  'Merrell'\r\n",
        "--     group by event_date; -- 423,365,870\r\n",
        "-- select count(*) from raw.ga4_events\r\n",
        "-- where property_brand =  'Merrell';\r\n",
        "\r\n",
        "select count(*), property_brand, brand_country\r\n",
        " from raw.ga4_events\r\n",
        "group by property_brand, brand_country;\r\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Counts Validation of GAU data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "-- select property_brand,brand_country,count(*) from raw.gua_events\r\n",
        "-- where event_date = '20230204' \r\n",
        "-- group by property_brand, brand_country;\r\n",
        "\r\n",
        "select count(*) from raw.gua_events \r\n",
        "where event_date = '20230204' and property_brand = 'Saucony'\r\n",
        "    and brand_country = 'US'"
      ]
    }
  ],
  "metadata": {
    "description": "ingest GA4 data",
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}