{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": "move brandProtection data from raw to gold",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Revision History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Change_date         revision_number     change_description                           author\r\n",
        "# 04/25/2024          1                   initial check-in                             Kranthi\r\n",
        "# 05/06/2024          2                   removed file count check                     Kranthi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType,DateType\r\n",
        "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"DYNAMIC\")\r\n",
        "from pyspark.sql.window import *\r\n",
        "from dateutil import tz\r\n",
        "from datetime import datetime\r\n",
        "#from pyspark.sql.functions import row_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "%run /utils/common_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "%run /utils/merge_data_notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# define file schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "schema = StructType([\r\n",
        "    StructField(\"Warehouse\", StringType(), True),\r\n",
        "    StructField(\"Plant\", StringType(), True),\r\n",
        "    StructField(\"PoNumber\", StringType(), True),\r\n",
        "    StructField(\"PoLine\", StringType(), True),\r\n",
        "    StructField(\"Material\", StringType(), True),\r\n",
        "    StructField(\"Size\", StringType(), True),\r\n",
        "    StructField(\"Width\", StringType(), True),\r\n",
        "    StructField(\"PackageBarCode\", StringType(), True),\r\n",
        "    StructField(\"ReferenceCaseNumber\", StringType(), True),     \r\n",
        "    StructField(\"DateReceived\", StringType(), True),\r\n",
        "    StructField(\"CartonNumber\", StringType(), True),\r\n",
        "    StructField(\"PickControlNumber\", StringType(), True),\r\n",
        "    StructField(\"ShipDate\", StringType(), True),\r\n",
        "    \r\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Validate the number of files and date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "class InvalidInputError(Exception):\r\n",
        "    pass\r\n",
        "\r\n",
        "file_cnt = 0\r\n",
        "file_dates = []\r\n",
        "today_dt = datetime.today().strftime('%Y-%m-%d')\r\n",
        "print(\"today_dt::\",today_dt)\r\n",
        "for j in mssparkutils.fs.ls(f'{raw_adls_path}AS400/BrandProtection/WM/'):\r\n",
        "  if j.size>0:  ## ignore archive folder\r\n",
        "    #file_dates.append(datetime.strftime(datetime.strptime(j.name.split('_')[0],'%Y%m%d'),'%Y-%m-%d'))\r\n",
        "    file_cnt = file_cnt+1\r\n",
        "#print('cnt::',file_cnt, 'file_date::',file_dates)\r\n",
        "print('no of files cnt::',file_cnt)\r\n",
        "#print(\"set to string date::\",''.join(set(file_dates))) ## convert set to string\r\n",
        "# try: \r\n",
        "#     #if (file_cnt == 5 and ''.join(set(file_dates)) ==  today_dt):\r\n",
        "#     if (file_cnt == 5):\r\n",
        "#         print('count is 5 and all dates belong to Today - continue processing')\r\n",
        "#     else:\r\n",
        "#         raise InvalidInputError(\"Incorrect date or # of files\") \r\n",
        "# except Exception as e:\r\n",
        "#     print(\"Error::\", str(e))\r\n",
        "#     raise           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Move the data to Gold layer - original code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "from_zone = tz.gettz('UTC')\r\n",
        "to_zone = tz.gettz('America/Chicago')\r\n",
        "dt_time = (datetime.now()).strftime('%Y-%m-%dT%H:%M:%SZ')\r\n",
        "\r\n",
        "utc = datetime.strptime(dt_time, \"%Y-%m-%dT%H:%M:%SZ\")\r\n",
        "print(\"utc::\",utc)\r\n",
        "utc = utc.replace(tzinfo=from_zone)\r\n",
        "cst = utc.astimezone(to_zone)\r\n",
        "print(\"utc2::\",utc)\r\n",
        "print(\"cst1::\",cst)\r\n",
        "print(\"cst2::\",cst.strftime('%H:%M:%S').replace(':',''))\r\n",
        "current_cst_time = cst.strftime('%H:%M:%S').replace(':','')\r\n",
        "print(\"current_cst_time\",current_cst_time)\r\n",
        "\r\n",
        "df_raw = spark.read.format('csv')\\\r\n",
        "         .option(\"header\", \"false\")\\\r\n",
        "         .schema(schema)\\\r\n",
        "         .load(f\"{raw_adls_path}AS400/BrandProtection/WM/\")\r\n",
        "df = df_raw.selectExpr('Warehouse'\r\n",
        ",'Plant'\r\n",
        ",'PoNumber'\r\n",
        ",'PoLine'\r\n",
        ",'Material'\r\n",
        ",'Size'\r\n",
        ",'Width'\r\n",
        ",'PackageBarCode'\r\n",
        ",'ReferenceCaseNumber'\r\n",
        ",'CartonNumber'\r\n",
        ",\"date_format(to_date(DateReceived,'yyyyMMdd'),'yyyy-MM-dd') as DateReceived\"\r\n",
        ",'PickControlNumber'\r\n",
        ",\"date_format(to_date(ShipDate,'yyyyMMdd'),'yyyy-MM-dd') as ShipDate\")\r\n",
        "display(df)\r\n",
        "if df.isEmpty():\r\n",
        "  print('dataframe is empty')\r\n",
        "else:\r\n",
        "  print('dataframe is not empty')  \r\n",
        "  dict_tables = {\r\n",
        "        \"AS400/BrandProtection/WM\": { \"source_df\": df\r\n",
        "                  ,\"where_condition\":\"\"\"target.CartonNumber = source.CartonNumber\"\"\"                        \r\n",
        "                  ,\"target_table\":\"lakedb_gold.brand_protection_wm_data\"  \r\n",
        "                  ,\"partition\":\"\"               \r\n",
        "                  ,\"path\": gold_adls_path + 'AS400/BrandProtection/WM'\r\n",
        "                  }\r\n",
        "                }\r\n",
        "  perform_merge(dict_tables)                   \r\n",
        "    \r\n",
        "#if file_cnt ==5:\r\n",
        "for j in mssparkutils.fs.ls(f\"{raw_adls_path}AS400/BrandProtection/WM/\"):\r\n",
        "  if j.size>0:  \r\n",
        "    print(f'moving ', j.name, ' to archive' )\r\n",
        "    file_name = j.name.replace('.csv','') \r\n",
        "    mssparkutils.fs.mv(f\"{raw_adls_path}AS400/BrandProtection/WM/{j.name}\", f\"{raw_adls_path}AS400/BrandProtection/WM/archive/{file_name}_{current_cst_time}.csv\",overwrite=True)    \r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Validate the end result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "--drop table lakedb_gold.brand_protection_wm_data;\r\n",
        "\r\n",
        "select * from lakedb_gold.brand_protection_wm_data;\r\n",
        "-- where snapshotdate = date_format(CURRENT_DATE,'yyyy-MM-dd')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Check the raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "spark.sql(f\"create table if not exists raw.brand_protection_wm_raw USING CSV LOCATION '{raw_adls_path}AS400/BrandProtection/WM/archive'\") \r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "select * from raw.brand_protection_wm_raw;"
      ]
    }
  ]
}