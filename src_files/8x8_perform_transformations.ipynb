{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from pyspark.sql.functions import udf, from_utc_timestamp ,col, explode,from_json,regexp_replace,split\r\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType, TimestampType\r\n",
        "from pyspark.sql import Row\r\n",
        "from pyspark.sql.functions import date_format,to_timestamp, to_date,regexp_replace\r\n",
        "import pyspark.sql.types as T\r\n",
        "from pyspark.sql.functions import broadcast\r\n",
        "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\",\"true\")\r\n",
        "spark.sql(\"SET spark.databricks.delta.schema.autoMerge.enabled = true\")\r\n",
        "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"true\")\r\n",
        "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")\r\n",
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\r\n",
        "spark.conf.set(\"spark.sql.adaptive.enabled\",\"true\")\r\n",
        "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"true\")\r\n",
        "spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\",\"true\")\r\n",
        "spark.conf.set(\"spark.databricks.adaptive.autoOptimizeShuffle.enabled\",\"true\")\r\n",
        "\r\n",
        "#spark.conf.set(\"spark.sql.shuffle.partitions\", 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# from datetime import datetime\r\n",
        "# import pytz\r\n",
        "  \r\n",
        "# # get the standard UTC time \r\n",
        "# UTC = pytz.utc\r\n",
        "  \r\n",
        "# # it will get the time zone \r\n",
        "# # of the specified location\r\n",
        "# EST = pytz.timezone('US/Eastern')\r\n",
        "  \r\n",
        "# # print the date and time in\r\n",
        "# # standard format\r\n",
        "# print(\"UTC in Default Format : \", \r\n",
        "#       datetime.now(UTC))\r\n",
        "  \r\n",
        "# print(\"EST in Default Format : \", \r\n",
        "#       datetime.now(EST))\r\n",
        "  \r\n",
        "# # print the date and time in \r\n",
        "# # specified format\r\n",
        "# datetime_utc = datetime.now(UTC)\r\n",
        "# print(\"Date & Time in UTC : \",\r\n",
        "#       datetime_utc.strftime('%Y:%m:%d %H:%M:%S %Z %z'))\r\n",
        "  \r\n",
        "# datetime_est = datetime.now(EST)\r\n",
        "# print(\"Date & Time in eST : \", \r\n",
        "#       datetime_est.strftime('%Y:%m:%d %H:%M:%S %Z %z'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "%run /utils/merge_data_notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# transform queue table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "print(raw_adls_path+'pcs/queue/')\r\n",
        "df_queue = spark.read.load(raw_adls_path+'pcs/queue/',format = \"delta\")\r\n",
        "#display(df_queue)\r\n",
        "df_queue_trans = df_queue.selectExpr('id as queueId', \r\n",
        "    'name as queueName', \"split(name,'[.]')[0] as department\"\r\n",
        "    ,\"split(name,'[.]')[1] as location\"\r\n",
        "    ,\"split(name,'[.]')[2] as language_cd\"\r\n",
        "    ,\"split(name,'[.]')[3] as brand\"\r\n",
        "    ,\"split(name,'[.]')[4] as context\",\"lastUpdateDate\", \"row_number() over(partition by id order by lastUpdateDate desc) as rn\")\\\r\n",
        "    .where(\"rn=1\")\\\r\n",
        "    .drop(\"rn\").distinct()\r\n",
        "\r\n",
        "#display(df_queue_trans)\r\n",
        "#print(df_queue.count())\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# get Agent DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "df_agents = spark.read.load(raw_adls_path+'pcs/agents/',format = \"delta\")\r\n",
        "df_na = spark.sql(\"select 'NA' as agent_id, 'NA' as agent_name, current_date as lastUpdateDate\")\r\n",
        "df_agents_trans = df_agents.selectExpr(\"id as agentId\",\"name as agentName\", \"lastUpdateDate\")\r\n",
        "df_agents_trans = df_agents_trans.union(df_na).distinct()\r\n",
        "df_agents_trans = df_agents_trans.selectExpr(\"agentId\", \"agentName\", \"lastUpdateDate\", \"row_number() over(partition by agentId order by lastUpdateDate desc) as rn\" ).where(\"rn=1\").drop(\"rn\")\r\n",
        "#df_agents_trans = df_agents_trans.where(\"rn=1\").drop(\"rn\")\r\n",
        "df_lang = spark.sql(f\"select language_short_nm as language_cd ,  language_long_nm as language from language_codes\")\r\n",
        "#display(df_agents_trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# perform transformation for PCS data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "#spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\r\n",
        "df_pcs = spark.read.load(raw_adls_path+'pcs/pcs/',format = \"delta\")\r\n",
        "\r\n",
        "#display(df_pcs)\r\n",
        "# getdigit-b85fb4cc-2c33-4d52-83fb-6608ee944564: \"\"NA\"\"\r\n",
        "# waitTime: \"\"4318.0\"\"\r\n",
        "# holdDuration: \"\"0.0\"\"\r\n",
        "# getdigit-d930a6f4-f5d8-44d5-8729-c3ab0c53aba4: \"\"NA\"\"\r\n",
        "# callerPhoneNumber: \"\"7737169265\"\"\r\n",
        "# muteDuration: \"0\"\r\n",
        "# timeInIVR: \"\"48342.0\"\"\r\n",
        "# callDate: \"\"02/22/2023 12:35:33\"\"\r\n",
        "# totalScore: \"0\"\r\n",
        "# queueList: \"\"[219]\"\"\r\n",
        "# callerName: \"\"MEEKS BERNARD\"\"\r\n",
        "# agentList: \"\"[ag36_SFf8LTB6LfUxWqyG9Aw]\"\"\r\n",
        "# agentCallHandlingDuration: \"\"456302.0\"\"\r\n",
        "# transactionId: \"\"941019\"\"\r\n",
        "## to convert data types , use to_date, to_timestamp\r\n",
        "## to have appropriate date formats MM/dd/yyyy use date_format\r\n",
        "## from_unixtimestamp(unix_timestamp()) -- also can be used as alternative to date_format\r\n",
        "## split('[.]' ) -- used to split a string with period \r\n",
        "df_pcs = df_pcs.selectExpr(\r\n",
        " \"loadDate as loadDate\"   \r\n",
        ",\"data.callId\" \r\n",
        ",\"to_date(data.callDate ,'MM/dd/yyyy') as callDate\"\r\n",
        ",\"date_format(to_timestamp(data.callDate,'MM/dd/yyyy HH:mm:ss'),'HH:mm:ss') as callTimeEST\"\r\n",
        ",\"from_unixtime(unix_timestamp(data.callDate,'MM/dd/yyyy HH:mm:ss'),'hh:mm:ss aa') as callTime12HrEST\"\r\n",
        ",\"data.callDate as callDatetimeEST\"\r\n",
        "#,\"from_utc_timestamp(to_timestamp(data.callDate,'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as CallDatetimeEST\"\r\n",
        "#,\"date_format(from_utc_timestamp(to_timestamp(data.callDate,'MM/dd/yyyy HH:mm:ss'),'US/Eastern'),'hh:mm:ss aa') as CallTime12HrEST\"\r\n",
        ",\"data.callerName\"\r\n",
        ",\"data.callerPhoneNumber\"\r\n",
        ",\"data.totalScore\"\r\n",
        ",\"data.question1 as Q1\"\r\n",
        ",\"data.question2 as Q2\"\r\n",
        ",\"data.agentList as agentList\"\r\n",
        ",\"data.queueList as queueList\"\r\n",
        ",\"data.transactionId as transactionIdOriginal\"\r\n",
        ",\"split(data.transactionId,' ')[0] as transactionId\"\r\n",
        ",\"case when size(split(regexp_replace(data.agentList, '(^\\[)|(\\]$)', ''),','))>1 then 'NA' else split(regexp_replace(data.agentList, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),',')[0] end as agentId\"\r\n",
        ",\"split(regexp_replace(data.queueList, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),',')[0] as queueId\"\r\n",
        ",\"questionLabel\"\r\n",
        ",\"data.agentCallHandlingDuration as agentCallDurationMs\"\r\n",
        ",\"data.callDuration as callDurationMs\"\r\n",
        ",\"data.holdDuration as holdDurationMs\"\r\n",
        ",\"data.muteDuration as muteDurationMs\"\r\n",
        ",\"data.timeInIVR as timeInIVRMs\"\r\n",
        ",\"data.waitTime as waitTimeMs\"\r\n",
        ",\"round(cast(data.agentCallHandlingDuration as float)/60000,2) as agentCallDuration\"\r\n",
        ",\"round(cast(data.callDuration as float)/60000,2) as callDuration\"\r\n",
        ",\"round(cast(data.holdDuration as float)/60000,2) as holdDuration\"\r\n",
        ",\"round(cast(data.muteDuration as float)/60000,2) as muteDuration\"\r\n",
        ",\"round(cast(data.timeInIVR as float)/60000,2) as timeInIVR\"\r\n",
        ",\"round(cast(data.waitTime as float)/60000,2) as waitTime\"\r\n",
        ",\"from_utc_timestamp(to_timestamp(loadDateTime,'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as loadDateTimeEST\"\r\n",
        ",\"row_number() over(partition by data.callId order by loadDateTime desc) as rn\"\r\n",
        ")\r\n",
        "\r\n",
        "df_pcs = df_pcs.join(broadcast(df_agents_trans),[\"agentId\"], \"left\").drop(\"lastUpdateDate\")\r\n",
        "df_pcs = df_pcs.join(broadcast(df_queue_trans),[\"queueId\"],\"left\").drop(\"lastUpdateDate\")\r\n",
        "df_pcs = df_pcs.join(broadcast(df_lang),[\"language_cd\"],\"left\").select(\"*\").where(\"rn = 1\")\r\n",
        "display(df_pcs.select('*'))\r\n",
        "#df_pcs.explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# transform historical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "print(raw_adls_path+'historical_analytics/')\r\n",
        "lst = mssparkutils.fs.ls(raw_adls_path+'historical_analytics/incremental/')#\r\n",
        "folder_name = [j.name for j in lst]\r\n",
        "folder_name = sorted(folder_name, reverse=True)[0]\r\n",
        "print(\"latest folder name::\",folder_name)\r\n",
        "df = spark.read.load(raw_adls_path+'historical_analytics/incremental/'+folder_name,format = \"delta\")\r\n",
        "spark.sql(f\"optimize delta.`{raw_adls_path}historical_analytics/incremental/{folder_name}`\")\r\n",
        "#df.dtypes\r\n",
        "#df = df.selectExpr('participants','queueWaitDuration').where(\"interactionId = 'int-18aafa907ce-TwSMHTchKftrlWWF9DQHK2zbZ-phone-03-wolverineworldwid01'\")\r\n",
        "#df = df.withColumn('queueWaitDuration',F.split(F.col('queueWaitDuration'),',')[0])\\\r\n",
        " #           .withColumn('queueWaitDuration',F.split(F.col('queueWaitDuration'),':')[1])\r\n",
        "#display(df)            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from pyspark.sql.functions import udf, col, explode\r\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\r\n",
        "from pyspark.sql import Row\r\n",
        "import pyspark.sql.functions as F\r\n",
        "\r\n",
        "#df = spark.read.load(raw_adls_path+'historical_analytics/',format = \"delta\")\r\n",
        "v_list = ['participantMute'\r\n",
        ",'participantMuteDuration'\r\n",
        ",'participantLongestMuteDuration'\r\n",
        ",'scheduleHours'\r\n",
        ",'TimetoAbandon'\r\n",
        ",'Transfers'\r\n",
        ",'interactionDuration'\r\n",
        ",'ivrTreatmentDuration'\r\n",
        ",'participantBusyDuration'\r\n",
        ",'participantHandlingDuration'\r\n",
        ",'participantHoldDuration'\r\n",
        ",'participantLongestHoldDuration'\r\n",
        ",'participantOfferDuration'\r\n",
        ",'participantProcessingDuration'\r\n",
        ",'participantWrapUpDuration'\r\n",
        ",'queueWaitDuration'\r\n",
        "]\r\n",
        "for j in v_list:\r\n",
        "    df = df.withColumn(j,F.split(F.col(j),',')[0])\\\r\n",
        "            .withColumn(j,F.split(F.col(j),':')[1])\r\n",
        "df_hist=df.withColumn('finishedTime',F.split(F.col('finishedTime'),',')[0])\\\r\n",
        "     .withColumn('finishedTime',F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col('finishedTime'), '\\\\{', ''),\"'value':\",''),\"'\",''))             \r\n",
        "   \r\n",
        "participants_schema = StructType([\r\n",
        "    StructField(\"participantAssignNumber\", StringType(), True),\r\n",
        "    #StructField(\"participantType\", StringType(), True),\r\n",
        "    StructField(\"participantId\", StringType(), True),\r\n",
        "    StructField(\"participantName\", StringType(), True),\r\n",
        "    StructField(\"participantOfferAction\", StringType(), True),\r\n",
        "    \r\n",
        "])\r\n",
        "\r\n",
        "df_hist = df_hist.selectExpr('loadDate', \r\n",
        " 'interactionId',\r\n",
        " 'blindTransferToAgent',\r\n",
        " 'blindTransferToQueue',\r\n",
        " #'campaignId',\r\n",
        " 'channelId',\r\n",
        " #'creationTime as creationTimeUTC',\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(creationTime,'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as creationTimeEST\",\r\n",
        " 'customerName',\r\n",
        " 'destination',\r\n",
        " \"regexp_replace(direction, '(.*)Dir', '$1') as direction\", \r\n",
        " 'dispositionAction',\r\n",
        " 'externalTransactionData',\r\n",
        " #'finishedTime as finishedTimeUTC',\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(finishedTime,'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as finishedTimeEST\",\r\n",
        " \"regexp_replace(regexp_replace(interactionLabels, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as interactionLabels\",\r\n",
        " 'interactionType',\r\n",
        " 'ivrTreatmentDuration/1000 as ivrTreatmentDuration ',\r\n",
        " #\"unix_timestamp(ivrTreatmentDuration,'H:mm:ss') as ivrTreatmentDuration\", #convert to seconds\r\n",
        " 'mediaType',\r\n",
        " 'originalInteractionId',\r\n",
        " 'originalTransactionId',\r\n",
        " 'origination',\r\n",
        " 'outboundPhoneCode',\r\n",
        " 'outboundPhoneCodeText',\r\n",
        " #'participantAssignNumber',\r\n",
        " 'participantBusyDuration/1000 as participantBusyDuration',\r\n",
        " 'participantHandlingDuration/1000 as participantHandlingDuration',\r\n",
        " #\"unix_timestamp(participantBusyDuration,'H:mm:ss') as participantBusyDuration\",\r\n",
        " #\"unix_timestamp(participantHandlingDuration,'H:mm:ss') as participantHandlingDuration\",\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(participantHandlingEndTime, 'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as participantHandlingEndTime\",\r\n",
        " 'participantHold',\r\n",
        " 'participantHoldDuration/1000 as participantHoldDuration',\r\n",
        " #\"unix_timestamp(participantHoldDuration,'H:mm:ss') as participantHoldDuration\", \r\n",
        " #\"regexp_replace(regexp_replace(participantId, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as agentId\",\r\n",
        " #\"unix_timestamp(participantLongestHoldDuration,'H:mm:ss') as participantLongestHoldDuration \",\r\n",
        "'participantLongestHoldDuration/1000 as participantLongestHoldDuration',\r\n",
        " #\"regexp_replace(regexp_replace(participantName, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as participantName\",\r\n",
        " #\"regexp_replace(regexp_replace(participantOfferAction, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as participantOfferAction\",\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(participantOfferActionTime, 'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as participantOfferActionTime\",\r\n",
        " #\"unix_timestamp(participantOfferDuration,'H:mm:ss') as participantOfferDuration\",\r\n",
        " 'participantOfferDuration/1000 as participantOfferDuration',\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(participantOfferTime, 'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as participantOfferTime\",\r\n",
        " 'participantProcessingDuration/1000 as participantProcessingDuration',\r\n",
        " #\"unix_timestamp(participantProcessingDuration, 'H:mm:ss') as participantProcessingDuration\",\r\n",
        " \"regexp_replace(regexp_replace(participantType, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as participantType\",\r\n",
        " 'participantWrapUpDuration/1000 as participantWrapUpDuration',\r\n",
        " #\"unix_timestamp(participantWrapUpDuration,'H:mm:ss') as participantWrapUpDuration \",\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(participantWrapUpEndTime, 'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as participantWrapUpEndTime\",\r\n",
        " \"split(regexp_replace(regexp_replace(queueId, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"',''),',')[0] as queueId\",\r\n",
        " #\"split(regexp_replace(regexp_replace(queueName, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"',''),',')[0] as queueName\",\r\n",
        " \"from_utc_timestamp(to_timestamp(date_format(queueTime,'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as queueTime\",\r\n",
        " 'queueWaitDuration/1000 as queueWaitDuration',\r\n",
        " #\"unix_timestamp(queueWaitDuration,'H:mm:ss') as queueWaitDuration\",\r\n",
        " \"date_format(time,'yyyy-MM-dd') as callDate\",\r\n",
        " #\"from_utc_timestamp(to_timestamp(date_format(time,'MM/dd/yyyy HH:mm:ss'),'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as time\",\r\n",
        " 'transactionId',\r\n",
        " 'warmTransfersCompleted',\r\n",
        " \"regexp_replace(regexp_replace(wrapUpCode, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as wrapUpCode\",\r\n",
        " \"regexp_replace(regexp_replace(wrapUpCodeId, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as wrapUpCodeId\",\r\n",
        " \"regexp_replace(regexp_replace(wrapUpCodeList, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as wrapUpCodeList\",\r\n",
        " \"regexp_replace(regexp_replace(wrapUpCodeListId, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as wrapUpCodeListId\",\r\n",
        " \"regexp_replace(regexp_replace(wrapUpCodeText, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as wrapUpCodeText\",\r\n",
        " \"regexp_replace(regexp_replace(wrapUpShortCode, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','') as wrapUpShortCode\",\r\n",
        " \"from_utc_timestamp(to_timestamp(loadDateTime,'MM/dd/yyyy HH:mm:ss'),'US/Eastern') as loadDateTimeEST\",\r\n",
        " \"row_number() over(partition by interactionId order by loadDateTime desc) as rn\",\r\n",
        " \"participantMute\",\r\n",
        " \"participantMuteDuration/1000 as participantMuteDuration\",\r\n",
        " \"participantLongestMuteDuration/1000 as participantLongestMuteDuration\",\r\n",
        " \"scheduleHours\",\r\n",
        " \"TimeToAbandon as timeToAbandon\",\r\n",
        " \"Transfers\",\r\n",
        " \"interactionDuration/1000 as interactionDuration\",\r\n",
        " \"participants\"\r\n",
        ")\r\n",
        "\r\n",
        "df_hist = df_hist.withColumn(\"parsed_data\", from_json(col(\"participants\"), ArrayType(participants_schema)))\r\n",
        "df_hist = df_hist.selectExpr(\"*\", \"cast(parsed_data.participantAssignNumber as string) as participantAssignNumber \",\"cast(parsed_data.participantId  as string) as agentId\",\"cast(parsed_data.participantName as string) as participantName\",\"cast(parsed_data.participantOfferAction as string) as participantOfferAction\")\r\n",
        "#df_hist = df_hist.join(df_agents_trans,[\"agentId\"], \"left\")\r\n",
        "df_hist = df_hist.drop(\"participants\",\"parsed_data\")\r\n",
        "df_hist = df_hist.where(\"rn=1\").join(broadcast(df_queue_trans),[\"queueId\"],\"left\")\r\n",
        "df_hist = df_hist.join(broadcast(df_lang),[\"language_cd\"],\"left\").select(\"*\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "display(df_hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "#display(df.select(from_json(col(\"participants\"),ArrayType(participants_schema))).where(\"interactionId = 'int-18aafa907ce-TwSMHTchKftrlWWF9DQHK2zbZ-phone-03-wolverineworldwid01'\") )\r\n",
        "#display(df_hist.selectExpr('loadDate','participantWrapUpDuration','queueWaitDuration','participantHandlingDuration','participantName').where(\"interactionId = 'int-18aafa907ce-TwSMHTchKftrlWWF9DQHK2zbZ-phone-03-wolverineworldwid01'\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "\r\n",
        "\r\n",
        "# refresh table  structured.cco_pcs;  \r\n",
        "# select distinct callDate from structured.cco_historical_analytics order by 1 desc;\r\n",
        "# select distinct callDate from structured.cco_pcs order by 1 desc;\r\n",
        "# select distinct date_format(time,'yyyy-MM-dd') from  delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/historical_analytics` order by 1 desc;\r\n",
        "# select distinct to_date(data.callDate ,'MM/dd/yyyy')  from  delta.`abfss://raw@azwwwnonproddevadapadls.dfs.core.windows.net/pcs/pcs` order by 1 desc;         \r\n",
        "# select 1 ; \r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Split InteractionLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "#display(df_hist.selectExpr(\"regexp_replace(regexp_replace(interactionLabels, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"','')\"))\r\n",
        "#display(df_hist.selectExpr(\"split(regexp_replace(regexp_replace(interactionLabels, '(^\\\\\\\\[)|(\\\\\\\\]$)', ''),'\\\\\"\"'\"\"',''),',')[0]\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Optimize the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#spark.sql(f\"optimize delta.`{structured_adls_path}historical_analytics`\")\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# create a dict for source and target tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dict_tables = {\r\n",
        "      \"pcs\": { \"source_df\": df_pcs\r\n",
        "                 ,\"where_condition\":\"target.callId = source.callId\"                        \r\n",
        "                 ,\"target_table\":\"lakedb_gold.cco_pcs\" \r\n",
        "                 ,\"partition\":\"\"\r\n",
        "                 ,\"path\": gold_adls_path + 'cco/pcs'\r\n",
        "                       \r\n",
        "                   }\r\n",
        "  ,\"historical_analytics\":\r\n",
        "                     { \r\n",
        "                       \"source_df\": df_hist\r\n",
        "                       ,\"where_condition\": \"target.interactionId = source.interactionId\"                     \r\n",
        "                       ,\"target_table\":\"lakedb_gold.cco_historical_analytics\"\r\n",
        "                       ,\"partition\":\"\"\r\n",
        "                       ,\"path\": gold_adls_path + 'cco/historical_analytics'\r\n",
        "                     }  \r\n",
        "  , \"agent\":\r\n",
        "  \r\n",
        "                    { \r\n",
        "                       \"source_df\": df_agents_trans\r\n",
        "                       ,\"where_condition\": \"target.agentId = source.agentId\"                    \r\n",
        "                       ,\"target_table\":\"lakedb_gold.cco_agent\"\r\n",
        "                       ,\"partition\":\"\"\r\n",
        "                       ,\"path\": gold_adls_path + 'cco/agent'\r\n",
        "                      \r\n",
        "                    }\r\n",
        "  , \"queue\":\r\n",
        "  \r\n",
        "                    { \r\n",
        "                       \"source_df\": df_queue_trans   \r\n",
        "                       ,\"where_condition\": \"target.queueId = source.queueId\"                   \r\n",
        "                       ,\"target_table\":\"lakedb_gold.cco_queue\"\r\n",
        "                       ,\"partition\":\"\"\r\n",
        "                       ,\"path\": gold_adls_path + 'cco/queue'\r\n",
        "                      \r\n",
        "                    }                 \r\n",
        "              }\r\n",
        "              \r\n",
        "\r\n",
        "#print(dict_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "perform_merge(dict_tables)"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}